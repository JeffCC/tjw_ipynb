{
 "metadata": {
  "name": "",
  "signature": "sha256:9a411ddecfbcbbef6f7ab364ac314adbe357836888b8c5992fc5603f81b02175"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import cv2\n",
      "import matplotlib.pyplot as plt\n",
      "import os\n",
      "import cv\n",
      "import sys"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.html.widgets import interact, interactive, fixed\n",
      "from IPython.display import clear_output, display, HTML\n",
      "from IPython.html import widgets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from io import BytesIO\n",
      "import PIL\n",
      "from IPython.display import display, Image\n",
      "\n",
      "def display_img_array(ima, cvt=None, **kwargs):\n",
      "    if cvt:\n",
      "        ima = cv2.cvtColor(ima, cvt)\n",
      "    im = PIL.Image.fromarray(ima)\n",
      "    bio = BytesIO()\n",
      "    im.save(bio, format='png')\n",
      "    display(Image(bio.getvalue(), format='png', **kwargs))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def normalize(im):    \n",
      "    im=cv2.cvtColor(im, cv2.CV_32F)\n",
      "    im=cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
      "    #im=cv2.equalizeHist(im)\n",
      "    return im"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def gray2vector(img):\n",
      "    v = img.reshape(-1).astype(float) \n",
      "    v = v - np.average(v) \n",
      "    return v/np.linalg.norm(v)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def diff_i(gray, i):\n",
      "    v1 = gray2vector(gray)\n",
      "    return np.dot(v1, slides_v[i])\n",
      "\n",
      "def compare_slides(gray, slides_v):\n",
      "    v1 = gray2vector(gray)\n",
      "    r = np.dot(slides_v, v1)\n",
      "    i = np.argmax(r)\n",
      "    return r[i], i\n",
      "\n",
      "def compare_absdiff(gray):\n",
      "    return sorted( (cv2.absdiff(slides[i], gray).sum() , i)  for i in range(len(slides)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def frame_to_time(f, r):\n",
      "    s = f/r\n",
      "    m = int(s/60)\n",
      "    s = s -60*m\n",
      "    return \"%d:%04.1f\"%(m,s)\n",
      "def sync_video( fn, p, slides, slides_v, threshold=0.8, step=10, dark=1000, STOP=-1, debug=False):\n",
      "    cap = cv2.VideoCapture(fn)\n",
      "    frame_rate = cap.get(cv.CV_CAP_PROP_FPS)\n",
      "    print \"frame_rate\", frame_rate\n",
      "    num_of_frames = cap.get(cv.CV_CAP_PROP_FRAME_COUNT)\n",
      "    frame_index =-1\n",
      "    last_slide = -1\n",
      "    last_start = -1\n",
      "    frame_list = []\n",
      "    progress = widgets.IntProgressWidget(min=0, max = num_of_frames - 1, value=0)\n",
      "    progress_text = widgets.TextWidget()\n",
      "    progress.set_css('background', 'black')\n",
      "    display(progress)\n",
      "    display(progress_text)\n",
      "    while cap.isOpened():\n",
      "        frame_index +=1\n",
      "        ret, frame = cap.read()\n",
      "        if not ret:\n",
      "            break        \n",
      "        if frame_index%step ==0:\n",
      "            if STOP!=-1 and frame_index > STOP:\n",
      "                break                        \n",
      "            gray = cv2.resize(normalize(frame)[p[0]:p[2],p[1]:p[3]], (256,256))        \n",
      "            darklevel = np.linalg.norm(gray.reshape(-1).astype(float)) \n",
      "            if darklevel < dark:\n",
      "                # too dark                \n",
      "                this_slide, v, i = -1, -1, 0\n",
      "            else:            \n",
      "                v, i = compare_slides(gray, slides_v)\n",
      "                this_slide = i if v > threshold else -1 \n",
      "            if debug:\n",
      "                if i>=0:\n",
      "                    frame2 = frame.copy()            \n",
      "                    frame2[p[0]:p[2], p[1]:p[3]] = cv2.resize(original_slides[i][q[0]:q[2], q[1]:q[3]], (p[3]-p[1], p[2]-p[0]))\n",
      "                    outp = np.concatenate( (frame2, cv2.addWeighted(frame,0.5,frame2, 0.5,0), frame), axis = 1)\n",
      "                    display_img_array(outp, width=1200, cvt=cv2.COLOR_BGR2RGB)\n",
      "                else:\n",
      "                    display_img_array(frame, width=400, cvt=cv2.COLOR_BGR2RGB)\n",
      "                print v,i\n",
      "            if frame_index%100 ==0:\n",
      "                progress.value = frame_index            \n",
      "                progress_text.value = \"%d/%d (%.1f)\"%(frame_index, num_of_frames, 100.0*frame_index/num_of_frames)\n",
      "            if this_slide != last_slide:\n",
      "                # update\n",
      "                frame_list.append( (last_start,  frame_index-1, last_slide))\n",
      "                \n",
      "                # display information                \n",
      "                if last_slide >=0:                \n",
      "                    fl = frame_list[-1]\n",
      "                    t1, t2 = frame_to_time(fl[0], frame_rate), frame_to_time(fl[1], frame_rate)\n",
      "                    print fl, \"=(%s, %s)\"%(t1,t2), \"v=%f\"%v, \"dark=%d\"%darklevel\n",
      "                last_start = frame_index                \n",
      "                if debug:\n",
      "                    p1 = cv2.resize(frame, (320,240))\n",
      "                    if i>=0:\n",
      "                        p2 = cv2.resize(original_slides[i], (320,240))\n",
      "                        p1 = np.concatenate( (p1, p2), axis =1)                \n",
      "                    if last_slide >= 0:\n",
      "                        display_img_array(cv2.cvtColor(p1, cv2.COLOR_BGR2RGB) , width=200)                 \n",
      "        last_slide = this_slide\n",
      "    # last update\n",
      "    frame_list.append( (last_start,  frame_index-1, last_slide))\n",
      "    cap.release()\n",
      "    return frame_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def write_file(fn, p,q, outfn, original_slides, sync_result, M=20, fourcc=\"XVID\", SKIP=None):\n",
      "    W,H = 1440, 960\n",
      "    W,H = 1920, 1080\n",
      "\n",
      "    cap = cv2.VideoCapture(fn)\n",
      "    SW, SH = int(cap.get(cv.CV_CAP_PROP_FRAME_WIDTH)), int(cap.get(cv.CV_CAP_PROP_FRAME_HEIGHT))\n",
      "    p2 = ( p[0]*H/SH, p[1]*W/SW, p[2]*H/SH, p[3]*W/SW)\n",
      "    pw, ph = p2[3]-p2[1], p2[2]-p2[0]\n",
      "    print p2, q\n",
      "    fourcc = cv.FOURCC(*fourcc)\n",
      "    num_of_frames = cap.get(cv.CV_CAP_PROP_FRAME_COUNT)\n",
      "    frame_rate = cap.get(cv.CV_CAP_PROP_FPS)\n",
      "    print \"frame_rate\", frame_rate\n",
      "    sys.stdout.flush()\n",
      "    out = cv2.VideoWriter(outfn, fourcc, frame_rate, (W, H))\n",
      "    frame_index =-1\n",
      "    last_slide = -1\n",
      "    last_start = -1\n",
      "    frame_list = []\n",
      "    result_index = 0\n",
      "    progress = widgets.IntProgressWidget(min=0, max = num_of_frames - 1, value=0)\n",
      "    progress_text = widgets.TextWidget()\n",
      "    progress.set_css('background', 'black')\n",
      "    display(progress)\n",
      "    display(progress_text)\n",
      "    while cap.isOpened():\n",
      "        frame_index +=1\n",
      "        ret, frame = cap.read()\n",
      "        if not ret:\n",
      "            break\n",
      "        while result_index < len(sync_result) and sync_result[result_index][1] < frame_index:\n",
      "            result_index += 1            \n",
      "        the_slide = (-1,-1,-1) if result_index >= len(sync_result) else sync_result[result_index]\n",
      "        if SKIP and the_slide[2] in SKIP:\n",
      "            the_slide = (-1,-1,-1)\n",
      "        original_frame = cv2.resize(frame, (W, H), interpolation = cv2.INTER_CUBIC)\n",
      "        if the_slide[2] >=0 and the_slide[1]-the_slide[0]>3*M:\n",
      "            slide = original_slides[the_slide[2]]\n",
      "            inner_frame = cv2.resize(slide[q[0]:q[2], q[1]:q[3]],  (pw, ph), interpolation = cv2.INTER_CUBIC )\n",
      "            d = min(frame_index-the_slide[0], the_slide[1]-frame_index)\n",
      "            out_frame = original_frame.copy()\n",
      "            out_frame[p2[0]:p2[2], p2[1]:p2[3]] = inner_frame\n",
      "            if d < M:\n",
      "                out_frame = cv2.addWeighted(out_frame, d*1.0/M , original_frame, 1- d*1.0/M, 0)\n",
      "        else:\n",
      "            out_frame = original_frame\n",
      "        out.write(out_frame)\n",
      "        if frame_index%100 ==0:\n",
      "            progress.value = frame_index            \n",
      "            progress_text.value = \"%d/%d (%.1f)\"%(frame_index, num_of_frames, 100.0*frame_index/num_of_frames)\n",
      "            if frame_index%10000 ==0:\n",
      "                disp_frame = np.concatenate((out_frame[:, :W/2], original_frame[:,W/2:]), axis=1)            \n",
      "                display_img_array(cv2.cvtColor(disp_frame, cv2.COLOR_BGR2RGB) , width=200) \n",
      "    cap.release()\n",
      "    out.release()\n",
      "            \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os.path\n",
      "def load_original_slides(name):\n",
      "    original_slides = []\n",
      "    i = 0\n",
      "    #progress = widgets.IntProgressWidget(min=0, max = num_of_frames - 1, value=0)\n",
      "    progress_text = widgets.TextWidget()\n",
      "    #progress.set_css('background', 'black')\n",
      "    #display(progress)\n",
      "    display(progress_text)\n",
      "    while True:         \n",
      "        progress_text.value = \"loading %d\"%i\n",
      "        img = cv2.imread(\"%s/%s-%d.png\"%(name, name, i))\n",
      "        if img is None:\n",
      "            break        \n",
      "        original_slides.append(img)\n",
      "        i+=1\n",
      "    print \"load original slides\", len(original_slides)\n",
      "    return original_slides\n",
      "def prepare_slides(original_slides, q, blur_factor):\n",
      "    normalized_slides = (cv2.blur(normalize(s), (blur_factor, blur_factor))  for s in original_slides)\n",
      "    slides = [cv2.resize(s[q[0]:q[2], q[1]:q[3]], (256,256), interpolation = cv2.INTER_CUBIC)  for s in normalized_slides]\n",
      "    slides_v = np.array([gray2vector(s) for s in slides])\n",
      "    print \"slides prepared\"\n",
      "    return slides, slides_v\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "original_slides, original_slides_name, result = None, None, None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def auto_sync(NAME, p1, q1, blur_factor, p2=None, q2=None,  threshold=0.8, step=10, dark=1500, STOP=-1, debug=False, \n",
      "              SKIP=None, M=20, PASS=[2,3],  fourcc=\"XVID\",  EXT=\"avi\"):\n",
      "    print \"NAME=\", NAME\n",
      "    fn_base = \"%s/%s\"%(NAME,NAME)\n",
      "    if  os.path.isfile(fn_base+\".mp4\"):\n",
      "        fn = fn_base+\".mp4\"\n",
      "    elif os.path.isfile(fn_base+\".avi\"):\n",
      "        fn = fn_base+\".avi\"\n",
      "    else:\n",
      "        print \"original video file does not exist\"\n",
      "        return\n",
      "    outfn = \"%s/better_%s.%s\"%(NAME, NAME, EXT)\n",
      "    global original_slides, result, original_slides_name    \n",
      "    if 0 in PASS or not os.path.isfile(\"%s/%s-0.png\"%(NAME,NAME)) : # 0 Extract PDF\n",
      "        print \"extract slides\"\n",
      "        sys.stdout.flush()\n",
      "        print os.system(\"convert -density 200 %s/%s.pdf  %s/%s.png\"%(NAME,NAME,NAME,NAME))\n",
      "    \n",
      "    if 1 in PASS or original_slides_name != NAME:\n",
      "        print \"load original png\"\n",
      "        original_slides = load_original_slides(NAME)\n",
      "        original_slides_name = NAME            \n",
      "\n",
      "    if 2 in PASS or original_slides_name != NAME: # Sync Video and Slides\n",
      "        print \"prepare slides\"\n",
      "        slides, slides_v = prepare_slides(original_slides, q1, blur_factor)        \n",
      "        print \"syncing video\"\n",
      "        result = sync_video(fn, p1, slides, slides_v, threshold=threshold, step=step, dark=dark, STOP=STOP, debug=debug)\n",
      "        print \"sync_video done\"   \n",
      "        \n",
      "    if p2 is None:   # full screen\n",
      "        p2 = (0,0,1080,1920)\n",
      "    if q2 is None:  # full screen\n",
      "        q2 = (0,0)+tuple(original_slides[0].shape[:2])\n",
      "        \n",
      "    if 3 in PASS or original_slides_name != NAME:\n",
      "        print \"start writing and converting\"\n",
      "        TEMP_OUT = \"temp_out.\"+EXT\n",
      "        write_file(fn, p1, q1, TEMP_OUT, original_slides, result, M=M, fourcc=fourcc, SKIP=SKIP)\n",
      "        print \"write done\"\n",
      "        sys.stdout.flush()\n",
      "        retcode = os.system(\"avconv -y -i %s -i %s -map 0:v -map 1:a -c:v copy -c:a copy %s\"%(TEMP_OUT, fn, outfn))\n",
      "        print \"covert done\", retcode"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p1,q1, blur_factor = (10, 160, 1080, 1754) , (0, 40, 2112, 2844) , 10 \n",
      "p2, q2 = p1, q1\n",
      "auto_sync(\"tulip\",  p1,q1, blur_factor, p2,q2, threshold=0.9, M=5, fourcc=\"x264\", EXT=\"mp4\", SKIP=[28], PASS=[3])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "NAME= tulip\n",
        "load original png\n",
        "load original slides"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 82\n",
        "start writing and converting\n",
        "(10, 160, 1080, 1754)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (0, 40, 2112, 2844)\n",
        "frame_rate 29.97002997\n"
       ]
      },
      {
       "ename": "TypeError",
       "evalue": "object of type 'NoneType' has no len()",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-12-3566e803c1be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mq1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblur_factor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m160\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1080\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1754\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2112\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2844\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mp2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mauto_sync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tulip\"\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mq1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblur_factor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mq2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfourcc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"x264\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEXT\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"mp4\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSKIP\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPASS\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-11-5dc7eeb44228>\u001b[0m in \u001b[0;36mauto_sync\u001b[1;34m(NAME, p1, q1, blur_factor, p2, q2, threshold, step, dark, STOP, debug, SKIP, M, PASS, fourcc, EXT)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;34m\"start writing and converting\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mTEMP_OUT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"temp_out.\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mEXT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mwrite_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTEMP_OUT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_slides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfourcc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfourcc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSKIP\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSKIP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;34m\"write done\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-8-2711e4633588>\u001b[0m in \u001b[0;36mwrite_file\u001b[1;34m(fn, p, q, outfn, original_slides, sync_result, M, fourcc, SKIP)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[1;32mwhile\u001b[0m \u001b[0mresult_index\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msync_result\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msync_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mresult_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mframe_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m             \u001b[0mresult_index\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mthe_slide\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mresult_index\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msync_result\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0msync_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mresult_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p1,q1,blur_factor = (10, 159, 1080, 1754) , (0, 39, 2112, 2844) , 16\n",
      "p2, q2 =  (10, 131, 1080, 1750) , (0, 0, 2115, 2844),\n",
      "auto_sync(\"graphtool\", p1,q1, blur_factor, p2, q2, threshold=0.8, SKIP=[90, 91,92,93,94,95,96,97], PASS=[3])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "NAME= graphtool\n",
        "load original png\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-54-f5a41fab43a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mq1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mblur_factor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m159\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1080\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1754\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m39\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2112\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2844\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mp2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq2\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m131\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1080\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1750\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2115\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2844\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mauto_sync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"graphtool\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mq1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblur_factor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSKIP\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m91\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m92\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m93\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m94\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m95\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m96\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m97\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPASS\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-52-1fbd4aa4ee24>\u001b[0m in \u001b[0;36mauto_sync\u001b[1;34m(NAME, p1, q1, blur_factor, p2, q2, threshold, step, dark, STOP, debug, SKIP, M, PASS, fourcc)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mPASS\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0moriginal_slides_name\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mNAME\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;34m\"load original png\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0moriginal_slides\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_original_slides\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNAME\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0moriginal_slides_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNAME\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-34-f5ea78678989>\u001b[0m in \u001b[0;36mload_original_slides\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mprogress_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"loading %d\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s/%s-%d.png\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p1,q1, blur_factor = (10, 159, 1080, 1750) , (0, 35, 2115, 2844), 16\n",
      "p2,q2 = (10, 138, 1080, 1750) , (0, 0, 2115, 2844) # test abcdefg\n",
      "auto_sync(\"ls\",  p1,q1, blur_factor, p2,q2, threshold=0.8, SKIP=[4,35,36] )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p1,q1, blur_factor = (211, 281, 958, 1723) , (0, 68, 2133, 2838) , 18\n",
      "p2,q2 = None, None \n",
      "auto_sync(\"fabric\",  p1,q1, blur_factor, p2,q2, threshold=0.8, SKIP=[19], M=40)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p1,q1, blur_factor = (145, 160, 954, 1751) , (0, 27, 1125, 2000) , 12\n",
      "p2, q2 = None, None\n",
      "auto_sync(\"vote\",  p1,q1, blur_factor, p2,q2, threshold=0.75, M=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p1,q1, blur_factor = (11, 144, 1080, 1752) , (0, 0, 1485, 2000) , 16\n",
      "p2, q2 = p1, q1\n",
      "auto_sync(\"mezz\",  p1,q1, blur_factor, p2,q2, threshold=0.9, M=20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p1,q1, blur_factor = (11, 135, 1080, 1753) , (0, 0, 2113, 2844) , 16\n",
      "p2, q2 = p1, q1\n",
      "auto_sync(\"summly\",  p1,q1, blur_factor, p2,q2, threshold=0.935, M=20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p1,q1, blur_factor = (19, 160, 1067, 1672) , (0, 80, 2070, 2844), 36\n",
      "p2, q2 = p1, q1\n",
      "auto_sync(\"StreetVoice\",  p1,q1, blur_factor, p2,q2, threshold=0.5, M=20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p1,q1, blur_factor = (19, 108, 1080, 1688) , (0, 0, 2084, 2844), 26\n",
      "p2, q2 = p1, q1\n",
      "auto_sync(\"grs\",  p1,q1, blur_factor, p2,q2, threshold=0.7, M=20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ip.set_css('background', 'black')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    }
   ],
   "metadata": {}
  }
 ]
}